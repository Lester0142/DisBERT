{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'label', 'sentence', 'POS', 'w_index'], dtype='object')\n",
      "size:  180175\n",
      "percentage of Metaphor:  13.196614402664075\n",
      "Average sentence length (unique sentences): 17.194816373374138\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/VUA18/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t', quoting=3) for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Check column names\n",
    "print(combined_data.columns)\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = combined_data['label'].value_counts()\n",
    "\n",
    "print(\"size: \", len(combined_data))\n",
    "print(\"percentage of Metaphor: \", label_counts[1]/len(combined_data)*100)\n",
    "\n",
    "# Remove duplicate sentences\n",
    "combined_data = combined_data.drop_duplicates(subset='sentence')\n",
    "\n",
    "# Calculate the average length of all sentences (unique sentences only)\n",
    "all_sentences_length = combined_data['sentence'].apply(lambda x: len(x.strip().split()))\n",
    "average_length_all = all_sentences_length.mean()\n",
    "print(f'Average sentence length (unique sentences): {average_length_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  182281\n",
      "percentage of Metaphor:  12.69797729878594\n",
      "Average sentence length (unique sentences): 16.38779174147217\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/VUA20/*.tsv')\n",
    "\n",
    "def read_fixed_tsv(file_path):\n",
    "    \"\"\"Reads a TSV file, ensuring the first line uses tabs (\\t) instead of spaces.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Fix the first line dynamically (convert spaces to tabs)\n",
    "    first_line_fixed = '\\t'.join(lines[0].strip().split())  # Ensure tab-separated headers\n",
    "    data_lines = lines[1:]  # Keep the rest of the file unchanged\n",
    "\n",
    "    # Convert the fixed content into a format pandas can read\n",
    "    fixed_content = first_line_fixed + '\\n' + ''.join(data_lines)\n",
    "    \n",
    "    # Read into pandas from in-memory string (without modifying file)\n",
    "    df = pd.read_csv(io.StringIO(fixed_content), sep='\\t', encoding='utf-8')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Read all fixed TSV files into a single DataFrame\n",
    "combined_data = pd.concat([read_fixed_tsv(file) for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = combined_data['label'].value_counts()\n",
    "\n",
    "print(\"size: \", len(combined_data))\n",
    "print(\"percentage of Metaphor: \", label_counts[1]/len(combined_data)*100)\n",
    "\n",
    "# Remove duplicate sentences\n",
    "combined_data = combined_data.drop_duplicates(subset='sentence')\n",
    "\n",
    "# Calculate the average length of all sentences (unique sentences only)\n",
    "all_sentences_length = combined_data['sentence'].apply(lambda x: len(x.split()))\n",
    "average_length_all = all_sentences_length.mean()\n",
    "print(f'Average sentence length (unique sentences): {average_length_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'label', 'sentence', 'pos', 'v_index'], dtype='object')\n",
      "size:  647\n",
      "percentage of Metaphor:  48.68624420401855\n",
      "Average sentence length (unique sentences): 6.904836193447738\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/MOH-X/CLS/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t', quoting=3) for file in tsv_files], ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "# Check column names\n",
    "print(combined_data.columns)\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = combined_data['label'].value_counts() \n",
    "print(\"size: \", len(combined_data))\n",
    "print(\"percentage of Metaphor: \", label_counts[1]/len(combined_data)*100)\n",
    "\n",
    "# Remove duplicate sentences\n",
    "combined_data = combined_data.drop_duplicates(subset='sentence')\n",
    "\n",
    "# Calculate the average length of all sentences (unique sentences only)\n",
    "all_sentences_length = combined_data['sentence'].apply(lambda x: len(x.split()))\n",
    "average_length_all = all_sentences_length.mean()\n",
    "print(f'Average sentence length (unique sentences): {average_length_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'label', 'sentence', 'pos', 'v_index'], dtype='object')\n",
      "size:  3737\n",
      "percentage of Metaphor:  43.53759700294354\n",
      "Average sentence length (unique sentences): 25.732445184568416\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/TroFi/CLS/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t', quoting=3) for file in tsv_files], ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "# Check column names\n",
    "print(combined_data.columns)\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = combined_data['label'].value_counts() \n",
    "print(\"size: \", len(combined_data))\n",
    "print(\"percentage of Metaphor: \", label_counts[1]/len(combined_data)*100)\n",
    "\n",
    "# Remove duplicate sentences\n",
    "combined_data = combined_data.drop_duplicates(subset='sentence')\n",
    "\n",
    "# Calculate the average length of all sentences (unique sentences only)\n",
    "all_sentences_length = combined_data['sentence'].apply(lambda x: len(x.split()))\n",
    "average_length_all = all_sentences_length.mean()\n",
    "print(f'Average sentence length (unique sentences): {average_length_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of Metaphor that Belongs to a Particular Word Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB     29.534904\n",
      "ADP      28.295524\n",
      "NOUN     21.025663\n",
      "ADJ       8.426031\n",
      "DET       6.139967\n",
      "ADV       3.481650\n",
      "PART      2.299203\n",
      "PROPN     0.516773\n",
      "PRON      0.135762\n",
      "PUNCT     0.096348\n",
      "NUM       0.030656\n",
      "INTJ      0.017518\n",
      "Name: POS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/VUA18/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t') for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Filter rows where label equals 1\n",
    "filtered_data = combined_data[combined_data['label'] == 1]\n",
    "\n",
    "# Count occurrences of each POS tag in the filtered data\n",
    "pos_counts = filtered_data['POS'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each POS tag\n",
    "pos_percentage = (pos_counts / pos_counts.sum()) * 100\n",
    "\n",
    "# Print the POS percentages\n",
    "print(pos_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB     26.898816\n",
      "ADP      24.284974\n",
      "NOUN     23.235116\n",
      "ADJ       8.861142\n",
      "DET       6.126329\n",
      "ADV       5.491230\n",
      "PROPN     2.471269\n",
      "AUX       2.138598\n",
      "PRON      0.155534\n",
      "INTJ      0.108010\n",
      "SCONJ     0.077767\n",
      "NUM       0.047524\n",
      "X         0.047524\n",
      "PART      0.034563\n",
      "PUNCT     0.021602\n",
      "Name: POS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/VUA20/*.tsv')\n",
    "\n",
    "def read_fixed_tsv(file_path):\n",
    "    \"\"\"Reads a TSV file, ensuring the first line uses tabs (\\t) instead of spaces.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Fix the first line dynamically (convert spaces to tabs)\n",
    "    first_line_fixed = '\\t'.join(lines[0].strip().split())  # Ensure tab-separated headers\n",
    "    data_lines = lines[1:]  # Keep the rest of the file unchanged\n",
    "\n",
    "    # Convert the fixed content into a format pandas can read\n",
    "    fixed_content = first_line_fixed + '\\n' + ''.join(data_lines)\n",
    "    \n",
    "    # Read into pandas from in-memory string (without modifying file)\n",
    "    df = pd.read_csv(io.StringIO(fixed_content), sep='\\t', encoding='utf-8')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Read all fixed TSV files into a single DataFrame\n",
    "combined_data = pd.concat([read_fixed_tsv(file) for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Filter rows where label equals 1\n",
    "filtered_data = combined_data[combined_data['label'] == 1]\n",
    "\n",
    "# Count occurrences of each POS tag in the filtered data\n",
    "pos_counts = filtered_data['POS'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each POS tag\n",
    "pos_percentage = (pos_counts / pos_counts.sum()) * 100\n",
    "\n",
    "# Print the POS percentages\n",
    "print(pos_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB    100.0\n",
      "Name: pos, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/MOH-X/CLS/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t') for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Filter rows where label equals 1\n",
    "filtered_data = combined_data[combined_data['label'] == 1]\n",
    "\n",
    "# Count occurrences of each POS tag in the filtered data\n",
    "pos_counts = filtered_data['pos'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each POS tag\n",
    "pos_percentage = (pos_counts / pos_counts.sum()) * 100\n",
    "\n",
    "# Print the POS percentages\n",
    "print(pos_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB    100.0\n",
      "Name: pos, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# KEY DESCRIPTIONS STATISTICS\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Find all .tsv files in the directory\n",
    "tsv_files = glob.glob('../data/TroFi/CLS/*.tsv')\n",
    "\n",
    "# Combine all .tsv files into a single DataFrame\n",
    "combined_data = pd.concat([pd.read_csv(file, delimiter='\\t', quoting=3) for file in tsv_files], ignore_index=True)\n",
    "\n",
    "# Filter rows where label equals 1\n",
    "filtered_data = combined_data[combined_data['label'] == 1]\n",
    "\n",
    "# Count occurrences of each POS tag in the filtered data\n",
    "pos_counts = filtered_data['pos'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each POS tag\n",
    "pos_percentage = (pos_counts / pos_counts.sum()) * 100\n",
    "\n",
    "# Print the POS percentages\n",
    "print(pos_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
